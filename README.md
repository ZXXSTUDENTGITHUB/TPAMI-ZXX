#Abstract
Graph Neural Networks (GNNs) have made significant strides in the analysis and modeling of complex networkdata, particularly excelling in graph and node classification tasks.However, the ”black-box” nature of GNNs impedes user understanding and trust, thereby restricting their broader application.This challenge has spurred a growing focus on demystifyingGNNs to make their decision-making processes more transparent.Traditional methods for explaining GNNs often rely on selectingsubgraphs and employing combinatorial optimization to generateunderstandable outputs. However, these methods are closelylinked to the inherent complexity of GNNs, leading to higher explanation costs. To address this issue, we introduce a lower complexity proxy model to explain GNNs. Our approach leverages knowledge distillation with inter-layer alignment, specifically targeting the challenge of over-smoothing and its detrimental impact on model explanation. Initially, we distill critical insights from complex GNN models into a more manageable proxy model. We then apply an inter-layer alignment-based distillation technique to ensure alignment between the proxy and the original model, facilitating the extraction of node or edge-level explanations within the proxy framework. We theoretically prove that the explanations derived from the proxy model are faithfulto both the proxy and the original model. Additionally, we showthat the upper bound of unfaithfulness between the proxy andthe original model remains consistent when the distillation erroris infinitesimal. This inter-layer alignment knowledge distillationtechnique enables the proxy model to retain the knowledgelearning and topological representation capabilities of the original model to the greatest extent. Experimental evaluations onnumerous real-world datasets confirm the effectiveness of ourmethod, demonstrating robust performance.
